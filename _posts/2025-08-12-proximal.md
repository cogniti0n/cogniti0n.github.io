---
title: Resolvents, Proximal Point Method, and Operator Splitting
date: 2025-08-12 05:50 +0800
description: Introduction to the notion of resolvents, and methods such as PPM and operator splitting.
categories: [optimization, convex-optimization]
tags: [lecture-notes]
math: true
toc: false
---

$$
    \def\argmin{\mathop{\mathrm{argmin}}}
    \def\argmax{\mathop{\mathrm{argmax}}}
    \def\expectation{\mathop{\mathbb{E}}}
    \def\dom{\mathrm{dom}}
    \def\R{\mathbb{R}}
    \def\find{\mathop{\mathrm{find}}}
$$

## Resolvents

We first define the _resolvent_ of an operator $A$.

> **Definition** The _resolvent_ of $A$ is defined as the operator
>
> $$
J_A = (I + A)^{-1}
> $$
>
> The _reflected resolvent_ of $A$ is defined as the operator
>
> $$
R_A = 2J_A - I
> $$

We often use $J_{\alpha A}$ and $R_{\alpha A}$ with $\alpha > 0$.

> **Theorem** If $A$ is maximal monotone, then $R_A$ is nonexpansive with domain $\R^n$, and $J_A$ is $1/2$-averaged with domain $\R^n$.

_proof_. Let $(x,u),(y,v) \in J_A$. Then by definition $x \in u + Au$ and $y \in v + Av$. By monotonicity,

$$
\langle (x-u) - (y-v), u-v \rangle \ge 0
$$

and

$$
\| (2u-x) - (2v-y) \|^2 = \| x-y \|^2 - 4 \langle (x-u) - (y-v) , u-v \rangle \le \| x-y \|^2
$$

Therefore, $R_A$ is nonexpansive and $J_A = \frac{1}{2} I + \frac{1}{2} R_A$.

The domain of $R_A$ and $J_A$ being $\R^n$ requires maximal monotone, and is a consequence of the Minty surjectivity theorem. This theorem is difficult to prove at this stage.

> **Theorem** The zero set of $A$ is closed and convex when $A$ is maximal monotone.

_proof_. $\mathrm{Zer}\,A = \mathrm{Fix}\,J_A$ since

$$
0 \in Ax \Leftrightarrow x \in x + Ax \Leftrightarrow J_Ax = x
$$

Since $J_A$ is nonexpansive, $\mathrm{Fix}\,J_A$ is closed convex. This proof relies on maximality, from the domain condition.

If $A$ is a symmetric matrix, then the eigenvalues of $A$ is in $[0,\infty)$. $J_A$ has eigenvalues in $(0,1]$, and $R_A$ has eigenvalues in $(-1,1]$.

> **Theorem** For CCP $f$ and $\alpha > 0$,
>
> $$
J_{\alpha \partial f} = \mathrm{Prox}_{\alpha f}
> $$

_proof_.

$$
\begin{aligned}
z = (I + \alpha \partial f)^{-1}(x) &\Leftrightarrow z + \alpha \partial f(z) \in x \\
                                    &\Leftrightarrow 0 \in \partial_z \left( \alpha f(x) + \frac{1}{2} \| z-x \|^2 \right) \\
                                    &\Leftrightarrow z = \argmin_{z} \left\{ \alpha f(z) + \frac{1}{2} \| z-x \|^2 \right\} \\
                                    &\Leftrightarrow z = \mathrm{Prox}_{\alpha f}(x)
\end{aligned}
$$

> **Proposition** If $g(u) = f^* (A^\top u)$, $f$ is CCP, and regularity conditions ($\mathrm{ri}\,\dom\,f^* \cap \mathrm{R}(A^\top) \ne \emptyset$) hold, then
>
> $$
v = \mathrm{Prox}_{\alpha g}(u) \Leftrightarrow \text{for some } x \in \argmin_x \left\{ f(x) - \langle u,Ax \rangle + \frac{\alpha}{2} \| Ax \|^2 \right\} \text{ , } v = u - \alpha Ax
> $$

_proof_. Use the theorem above, then $v = J_{\alpha \partial g}(u)$. Therefore, the following holds.

$$
\begin{aligned}
v = (I+\alpha\partial g)^{-1}(u) &\Leftrightarrow u \in v + \alpha g(v) = v + \alpha A \partial f^* (A^\top v) \\
                                 &\Leftrightarrow \exists \, x \in \partial f^*(A^\top u) \text{ s.t. } u = v + \alpha Ax \\
\end{aligned}
$$

Now from the definition of the dual function,

$$
A^\top v = A^\top (u - \alpha Ax) \in \partial f(x)
$$

which is equivalent to

$$
x \in \argmin_x \left\{ f(x) - \langle u,Ax \rangle + \frac{\alpha}{2} \| Ax \|^2 \right\}
$$

If $C \in \R^n$ is nonempty and closed convex, then $J_{\partial \delta_C} = \mathrm{Prox}_{\delta_C}$ is the projection onto $C$, i.e., $\Pi_C$. Therefore the resolvent generalizes projection.

Here is an example that we will use later on. I omitted the proof.

> **Theorem** Consider the Lagrangian for an optimization problem with linear constraints,
>
> $$
L(x,u) = f(x) + \langle u,Ax-b \rangle
> $$
>
> Then, the resolvent of $\partial L$, which is defined as
>
> $$
\partial L = \begin{bmatrix} \partial_x L \\ \partial_u (-L) \end{bmatrix}
> $$
>
> can be computed using the following identity.
>
> $$
J_{\alpha \partial L}(x,u) = (y,v) \Leftrightarrow \text{for some } y \in \argmin_{z} \left\{ L_\alpha(z,u) + \frac{1}{2\alpha} \| z-x \|^2 \right\} \text{ , } v = u + \alpha (Ay-b)
> $$
>
> where
>
> $$
L_\alpha(x,u) = L(x,u) + \frac{1}{2}\alpha \|Ax-b \|^2
> $$

Below are some identities that hold for resolvents. Let $A$ be maximal monotone and $\alpha > 0$, then

- If $B(x) = A(x) + t$, then $J_{\alpha B}(u) = J_{\alpha A}(u-\alpha t)$
- If $B(x) = A(x-t)$, then $J_{\alpha B}(u) = J_{\alpha A}(u-t)+t$
- If $B(x) = -A(t-x)$, then $J_{\alpha B}(u) = t-J_{\alpha A}(t-u)$
- (_Inverse resolvent identity_)

$$
J_{\alpha^{-1}A}(x) + \alpha^{-1}J_{\alpha A^{-1}}(\alpha x) = x
$$

- If $\alpha = 1$ in the identity above, then $J_{A} + J_{A^{-1}} = I$.
- If $f$ is CCP in the identity above, then
$$\mathrm{Prox}_{\alpha^{-1}f}(x) + \alpha^{-1}\mathrm{Prox}_{\alpha f^* }(\alpha x) = x$$
- (_Reflected resolvent identity 1_)

$$
R_{\alpha A} = (I - \alpha A)(I + \alpha A)^{-1}
$$

The proof uses a lemma which will be useful later on.

> **Lemma** If $x \in \dom{T}$ and $T^{-1}$ is single-valued, then $T^{-1}Tx = x$.

_proof_. There exists some $y$ such that $y \in Tx$. Therefore, $x \in T^{-1}y \in T^{-1}(Tx)$. Now we prove that such $x$ is unique. Suppose $\tilde{x} \in T^{-1}Tx$. Then, there exists some $y$ such that $\tilde{x} = T^{-1}y$, and therefore $y \in Tx$, and consequently $T^{-1}y=x$. Therefore, $\tilde{x} = x$ and $x$ is the unique element of $T^{-1}Tx$.

Now we prove the identity stated above.

_proof_.

$$
\begin{aligned}
R_{\alpha A} &= 2(I + \alpha A)^{-1} - I \\
             &= 2(I + \alpha A)^{-1} - (I + \alpha A)(I + \alpha A)^{-1} \\
             &= (I - \alpha A)(I + \alpha A)^{-1}
\end{aligned}
$$

The second line holds from the lemma above and the maximal monotone property of $A$.

- (_Reflected resolvent identity 2_)

$$
R_{\alpha A}(I + \alpha A) = I - \alpha A
$$

_proof_. For some $x \in \dom\,A$ (if $x \notin \dom\,A$, then both sides are empty sets),

$$
\begin{aligned}
R_{\alpha A}(I + \alpha A)(x) &= 2(I + \alpha A)^{-1}(I + \alpha A)(x) - (I + \alpha A)(x) \\
                              &= 2I(x) - (I + \alpha A)(x) \\
                              &= (I - \alpha A)(x)
\end{aligned}
$$

Again, the second line holds from the lemma above and maximal monotone property of $A$.

## Proximal Point Method

Consider the problem of finding zeros of a maximally monotone operator $A$. Then such a problem is equivalent to finding the fixed point of $J_{\alpha A}$, for some $\alpha > 0$.

> **Definition** The fixed point iteration
>
> $$
x^{k+1} = J_{\alpha A}(x^k)
> $$
>
> is the proximal point method (PPM) or proximal minimization.

Since $J_{\alpha A}$ is averaged, PPM converges given the existance of a solution. Below are some examples of problems that can be solved using PPM.

### Method of Multipliers (MM)

Consider the primal-dual pair generated by

$$
L(x,u) = f(x) + \langle u, Ax-b \rangle
$$

Then recall the example above - the augmented Lagrangian

$$
L_\alpha(x,u) = L(x,u) + \frac{1}{2}\alpha \|Ax-b \|^2
$$

Then our goal is, given a primal-dual solution pair exist, to find the zero of $\partial L$. Consequently, we want to find the fixed points of $J_{\alpha \partial A}$. Therefore, we can use the results from the example above. First assume the regularity condition holds. Then write $g(u) = f^* (=A^\top u) + b^\top u$. We end up with the following fixed-point iteration:

$$
x^{k+1} \in \argmin_{x}\,L_\alpha(x,u^k)
$$

$$
u^{k+1} = u^k + \alpha (Ax^{k+1} - b)
$$

If a dual solution exists and $\alpha > 0$, then $u^k \to u^\star $.

#### Proximal Method of Multipliers

We consider a similar fixed point iteration:

$$
x^{k+1} = \argmin_x \left\{ L_\alpha(x,u^k) + \frac{1}{2\alpha} \| x-x^k \|^2 \right\}
$$

$$
u^{k+1} = u^k + \alpha (Ax^{k+1} - b)
$$

If total duality holds and $\alpha > 0$, then $x^k \to x^\star$ and $u^k \to u^\star$.

## Operator Splitting

Operator splitting refers to the technique where we split a monotone inclusion problem into smaller and simpler components. For example, we want to solve problems in the form $x \in \mathrm{Zer}\,(A+B)$ into fixed-point iterations from $A$, $B$, ... and their resolvents. There are many variants regarding operator splitting.

### Forward-Backward Splitting (FBS)

Consider the problem

$$
\find_{x \in \R^n} \quad 0 \in (A+B)x
$$

where $A$ and $B$ are maximal monotone, and $A$ is single-valued. For some $\alpha > 0$,

$$
\begin{aligned}
0 \in (A+B)x &\Leftrightarrow 0 \in (I + \alpha B)x - (I - \alpha A)x \\
             &\Leftrightarrow (I - \alpha A)x \in (I + \alpha B)x \\
             &\Leftrightarrow x = J_{\alpha B}(I - \alpha A)x
\end{aligned}
$$

where the second line holds because $A$ is single-valued. We have transformed the problem into a fixed-point problem. Assume $A$ is $\beta$-cocoersive and $\alpha \in (0,2\beta)$. Forward step $I - \alpha A$ and backward step $(I + \alpha B)^{-1}$ are averaged. Therefore, the fixed point iteration

$$
x^{k+1} = J_{\alpha B}(x^k - \alpha A x^k)
$$

converges if $\alpha \in (0,2\beta)$ and $\mathrm{Zer}\,(A+B) \ne \emptyset$.

#### Backward-Forward Splitting (BFS)

Permute the order of FBS.

$$
\begin{aligned}
0 \in (A+B)x &\Leftrightarrow (I - \alpha A)x \in (I + \alpha B)x \\
             &\Leftrightarrow z = (I - \alpha A)x \text{, } z \in (I + \alpha B)x \\
             &\Leftrightarrow z = (I - \alpha A)x \text{, } J_{\alpha B}z = x\\
             &\Leftrightarrow z = (I - \alpha A)J_{\alpha B}z \text{, } J_{\alpha B}z = x
\end{aligned}
$$

Therefore we construct the following FPI.

$$
x^{k+1} = J_{\alpha B}z^k
$$

$$
z^{k+1} = x^{k+1} - \alpha Ax^{k+1}
$$

Such a FPI converges if $\alpha \in (0,2\beta)$ and $\mathrm{Zer}\,(A+B) \ne \emptyset$.

#### Peaceman-Rachford Splitting (PRS)

Consider

$$
\find_{x \in \R^n} \quad 0 \in (A+B)x
$$

where $A$ and $B$ are maximal monotone. Use the identity $R_{\alpha A} = (I - \alpha A)(I + \alpha A)^{-1}$ proved above.

$$
\begin{aligned}
0 \in (A+B)x &\Leftrightarrow 0 \in (I + \alpha A)x - (I - \alpha B)x \\
             &\Leftrightarrow 0 \in (I + \alpha A)x - R_{\alpha B}(I + \alpha B)x \\
             &\Leftrightarrow 0 \in (I + \alpha A)x - R_{\alpha B}x \text{ for some } z \in (I + \alpha B)x \\
             &\Leftrightarrow R_{\alpha B}z \in (I + \alpha A)J_{\alpha B}z \text{ , } x = J_{\alpha B}z \\
             &\Leftrightarrow J_{\alpha A}R_{\alpha B}z = J_{\alpha B}z \text{ , } x = J_{\alpha B}z \\
             &\Leftrightarrow 2J_{\alpha A}R_{\alpha B}z - z = R_{\alpha B}z \text{ , } x = J_{\alpha B}z \\
             &\Leftrightarrow 2J_{\alpha A}R_{\alpha B}z - R_{\alpha B}z = z \text{ , } x = J_{\alpha B}z \\
             &\Leftrightarrow R_{\alpha A}R_{\alpha B}z = z \text{ , } x = J_{\alpha B}z
\end{aligned}
$$

Therefore, we can construct the following fixed point iteration $z^{k+1} = R_{\alpha A}R_{\alpha B}(z^k)$. Since $R_{\alpha A}$ and $R_{\alpha B}$ are nonexpansive, we need to average the operator in order to guarantee convergence.

#### Douglas-Rachford Splitting (DRS)

We perform fixed point iteration using $\frac{1}{2}I + \frac{1}{2}R_{\alpha A}R_{\alpha B}$ and construct the following fixed point iteration.

$$
x^{k+1/2} = J_{\alpha B}(z^k)
$$

$$
x^{k+1} = J_{\alpha A}(2x^{k+1/2} - z^k)
$$

$$
z^{k+1} = z^k + x^{k+1} - x^{k+1/2}
$$

Such an FPI converges for any $\alpha > 0$ if $\mathrm{Zer}\,(A+B) \ne \emptyset$.

#### Davis-Yin Splitting (DYS)

Consider

$$
\find_{x \in \R^n} \quad 0 \in (A+B+C)x
$$

where $A$, $B$, $C$ are maximal monotone, and $C$ is single-valued. For a given $\alpha > 0$, we can show, using the methods stated above, that the following statement holds.

$$
0 \in (A+B+C) x \Leftrightarrow \frac{1}{2}I + \frac{1}{2}Tz = z \text{ , } x = J_{\alpha B}z
$$

where $T = R_{\alpha A}(R_{\alpha B} - \alpha C J_{\alpha B}) - \alpha C J_{\alpha B}$. Therefore, our goal is to find the fixed points of the following operator.

$$
\frac{1}{2}I + \frac{1}{2}T = I - J_{\alpha B} + J_{\alpha A}(R_{\alpha B} - \alpha C J_{\alpha B})
$$

If $C$ is $\beta$-cocoersive and $\alpha \in (0,2\beta)$, then $(1/2)I + (1/2)T$ is averaged (the proof will not be stated here). Therefore the following FPI converges for $\alpha \in (0,2\beta)$ if $\text{Zer}\,(A+B+C) \ne \emptyset$.

$$
x^{k+1/2} = J_{\alpha B}(z^k)
$$

$$
x^{k+1} = J_{\alpha A}(2x^{k+1/2} - z^k - \alpha C x^{k+1/2})
$$

$$
z^{k+1} = z^k + x^{k+1} - x^{k+1/2}
$$

DYS reduces to

- BFS when $A=0$
- FBS when $B=0$
- DRS when $C=0$
- PPM when $A=C=0$

## Applications of Base Splittings

### Proximal Gradient Method

Consider the problem

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad f(x) + g(x)
$$

where $f$, $g$ are CCP and $f$ is differentiable. Then, we can see that $x \in \argmin\,(f+g) \Leftrightarrow \mathrm{Zer}\,(\nabla f + \partial g)$. By using FBS, we obtain the following fixed point iteration.

$$
x^{k+1} = \mathrm{Prox}_{\alpha g}(x^k - \alpha \nabla f(x^k))
$$

Such an FPI is called the proximal gradient method. If a minimizer exists, $f$ is $L$-smooth, and $\alpha \in (0,2/L)$, then $x^k \to x^\star$. This FPI is equivalent to

$$
x^{k+1} = \argmin_x \left\{ f(x^k) + \langle \nabla f(x^k), x-x^k \rangle + g(x) + \frac{1}{2\alpha} \| x-x^k \|^2_2 \right\}
$$

which uses a first-order approximation of $f$ about $x^k$. When $g = \delta_C$ (representing a convex feasible set), the proximal gradient method becomes

$$
x^{k+1} = \Pi_C (x^k - \alpha \nabla f(x^k))
$$

which is the projected gradient method.

#### DRS For Convex Optimization

Consider the Lagrangian $L(x,u) = f(x) + \langle x,u \rangle - g^* (u)$, where $f$ and $g$ are CCP. The primal problem generated by this Lagrangian is

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad f(x) + g(x)
$$

When total duality holds, the primal problem is equivalent to

$$
\find_{x \in \R^n} \quad 0 \in (\partial f + \partial g)x
$$

This is because total duality ensures the existence of a minimizer of $f+g$, and therefore a zero of $\partial f + \partial g$.

> **Theorem** When total duality holds, $\argmin(f+g) = \mathrm{Zer}\,(\partial f + \partial g) \ne \emptyset$ if and only if total duality holds for the primal-dual pair generated by the Lagrangian
>
> $$
L(x,u) = f(x) + \langle x,u \rangle - g^* (u)
> $$
>
> where $f$ and $g$ are CCP. Therefore,
>
> $$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad f(x) + g(x) \Leftrightarrow \mathop{\mathrm{find}}_{x \in \R^n} \quad 0 \in (\partial f + \partial g)(x)
> $$

_proof_. ($\Rightarrow$) Assume total duality holds. Then $x^\star \in \argmin(f+g)$ if and only if $(x^\star,u^\star)$ is a saddle point of the Lagrangian

$$
L(x,u) = f(x) + \langle x,u \rangle - g^* (u)
$$

for some $u^\star \in \R^n$. $(x^\star, u^\star)$ is a saddle point of $L$ if and only if $0 \in \partial L(x^\star,u^\star) \equiv [\partial_x L \quad \partial_u(-L)]^\top$.

$$
\begin{aligned}
0 \in \partial_x L(x^\star, u^\star), 0 \in \partial_u(-L)(x^\star,u^\star) &\Leftrightarrow -u^\star \in \partial f(x^\star), u^\star \in \partial g(x^\star) \\
&\Leftrightarrow -u^\star \in \partial f(x^\star), u^\star \in \partial g(x^\star) \\
&\Leftrightarrow 0 \in (\partial f +\partial g)(x^\star)
\end{aligned}
$$

Therefore, $\argmin(f+g)$ is nonempty. ($\Rightarrow$) Now assume that $\argmin(f+g)$ is nonempty. Then any $x^\star \in \argmin(f+g)$ satisfies $0 \in (\partial f + \partial g)(x^\star)$. Using the chain of arguments proposed above, there exists a $u^\star$ such that $(x^\star,u^\star)$ is a saddle point of $L$. Thus, total duality holds.

Then we apply DRS for this problem, which generates the following FPI.

$$
x^{k+1/2} = \mathrm{Prox}_{\alpha g}(z^k)
$$

$$
x^{k+1} = \mathrm{Prox}_{\alpha f}(2x^{k+1/2} - z^k)
$$

$$
z^{k+1} = z^k + x^{k+1} - x^{k+1/2}
$$

If total duality holds and $\alpha >0$, then $x^k \to x^\star$ and $x^{k+1/2} \to x^\star$. We can furthermore show that $z^k \to z^\star = x^\star + \alpha u^\star$.

The two examples shown above are similar but have different requirements.

- DRS requires $f$ and $g$ to be CCP and $\alpha > 0$.
- Proximal gradient method requires $f$ and $g$ to be $L$-smooth and $\alpha \in (0,2/L)$, so it requires a stronger condition.
- DRS is useful when evaluating
$$\mathrm{Prox}_{\alpha f}$$
and
$$\mathrm{Prox}_{\alpha g}$$
are easy.
- Proximal gradient is useful when evaluating $\nabla f$ and $\mathrm{Prox}_{\alpha g}$ are easy.
- Proximal point method is useful when evaluating $\mathrm{Prox}_{\alpha (f+g)}$ is easy.

#### LASSO and ISTA

The LASSO problem (least absolute shrinkage and selection operator) is the following L1-regularized optimization problem. We specifically look at the linear regression with L1 regularization. Consider $A \in \R^{m \times n}$, $b \in \R^n$, %\lambda > 0$, and the following LASSO problem.

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad \frac{1}{2} \| Ax-b \|^2 + \lambda \| x \|_1
$$

Then apply DRS to obtain the following FPI.

$$
x^{k+1/2} = (I + \alpha A^\top A)^{-1} (z^k + \alpha A^\top b)
$$

$$
x^{k+1} = S(2x^{k+1/2} - z^k ; \alpha \lambda) \equiv \mathrm{Prox}_{\alpha \lambda \| \cdot \|_1}(2x^{k+1/2}-z^k)
$$

$$
z^{k+1} = z^k + x^{k+1} - x^{k+1/2}
$$

Such an FPI converges for any $\alpha > 0$. Using FBS, we obtain a simpler but more restrictive FPI. For $0 < \alpha 2/\lambda_{\mathrm{max}}(A^\top A)$,

$$
x^{k+1} = S(x^k - \alpha A^\top (Ax^k - b) ; \alpha \lambda) \equiv \mathrm{Prox}_{\alpha \lambda \| \cdot \|_1} (x^k - \alpha A^\top (Ax^k - b))
$$

converges. This method is called ISTA (Iterative Shrinkage-Thresholding Algorithm).

Comparing the two methods above, DRS uses the matrix inverse $(I + \alpha A^\top A)^{-1}$, which can be expensive to calculate when dimensions are large. FBS is therefore more computationally efficient.

#### DYS For Convex Optimization

Consider the Lagrangian

$$
L(x,u) = f(x) + h(x) + \langle x,u \rangle - g^* (u)
$$

which generates the primal problem

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad f(x) + g(x) + h(x)
$$

Then apply DYS, which generates the following fixed-point iteration.

$$
x^{k+1/2} = \mathrm{Prox}_{\alpha g}(z^k)
$$

$$
x^{k+1} = \mathrm{Prox}_{\alpha f}(2x^{k+1/2} - z^k - \alpha \nabla h(x^{k+1/2}))
$$

$$
z^{k+1} = z^k + x^{k+1} - x^{k+1/2}
$$

If total duality holds, $h$ is $L$-smooth, and $\alpha \in (0,2/L)$, then $x^k \to x^\star$ and $x^{k+1/2} \to x^\star$. We can furthermore show that $z^k \to z^\star = x^\star + \alpha u^\star$.

## Some Discussions

- Fixed-point encoding establishes a correspondence between solutions of a monotone inclusion problem and fixed points of a related operator.
- We use the resolvent as it is single-valued, and therefore algorithmically actionable. It is also computationally convenient.
- We implicitly assumed $\dom\,T = \R^n$, which is satisfied with resolvents of maximal monotone operators. For non-maximal monotone operators, we cannot efficiently compute the resolvent.
- Base splitting methods are useful when the subroutines are efficient to compute. Since there are usually more than one method, the goal is to find the most computationally efficient components.

Here are some examples regarding the last point. Consider the following optimization problem.

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad \sum^m_{i=1} g_i(x)
$$

where $g_1,\dots,g_m$ are CCP. Then this problem is equivalent to

$$
\begin{aligned}
\mathop{\mathrm{minimize}}_{\mathbf{x} \in \R^{n \times m}} \quad &\sum^{m}_{i=1} g_i(x_i) \\
\text{subject to} \quad &\mathbf{x} \in C
\end{aligned}
$$

where $\mathbf{x} = [x_1,\dots,x_m]$ and
$$C = \{ [x_1,\dots,x_m] \, | \, x_1=\cdots=x_m \}$$
 is the _consensus set_. Then such a minimization problem is equivalent to

$$
\mathop{\mathrm{find}}_{\mathbf{x} \in \R^{n \times m}} \quad 0 \in \begin{bmatrix} \partial g_1(x_1) \\ \vdots \\ \partial g_m(x_m) \end{bmatrix} + \partial \delta_C (\mathbf{x})
$$

assuming the regularity condition $\cap^m_{i=1} \text{int dom}\, g_i \ne \emptyset$ holds. This problem can be solved using DRS. Projection onto the consensus set is a simple averaging between the vector elements, i.e.,

$$
\Pi_C \mathbf{x} = \bar{\mathbf{x}} = (\bar{x},\dots,\bar{x}), \quad \bar{x} = \frac{1}{m} \sum^m_{i=1} x_i
$$

Then DRS generates the following FPI.

$$
x_i^{k+1} = \mathrm{Prox}_{\alpha g_i}(2\bar{z}^k - z_i^k) \quad \text{for } i = 1,\dots,m
$$

$$
\mathbf{z}^{k+1} = \mathbf{z}^k + \mathbf{x}^{k+1} - \bar{\mathbf{z}}^k
$$

Such an FPI converges for any $\alpha > 0$, if the regularity condition above holds and a solution exists. This method is well-suited for parallel distributed computing.

Consider the following optimization problem.

$$
\mathop{\mathrm{minimize}}_{x \in \R^n} \quad \sum^m_{i=1} (f_i(x) + g_i(x))
$$

where $g_1,\dots,g_m$ are CCP and $f_1,\dots,f_m$ are $L$-smooth. Using the consensus technique, this is equivalent to

$$
\begin{aligned}
\mathop{\mathrm{minimize}}_{\mathbf{x} \in \R^{n \times m}} \quad& \sum^m_{i=1} f_i(x_i) + \sum^m_{i=1} g_i(x_i) \\
\text{subject to} \quad& \mathbf{x} \in C
\end{aligned}
$$

To solve this we use DYS and obtain the following FPI.

$$
x_i^{k+1} = \mathrm{Prox}_{\alpha g_i} (2\bar{z}^k - z^k_i - \alpha \nabla f_i(\bar{z}^k)) \quad \text{for } i = 1,\dots,m
$$

$$
\mathbf{z}^{k+1} = \mathbf{z}^k + \mathbf{x}^{k+1} - \bar{\mathbf{z}}^k
$$

This FPI converges if regularity conditions hold and $\alpha \in (0,2/L)$.

## References

[1] Ryu, Ernest K., and Wotao Yin. 2022. Large-Scale Convex Optimization. Cambridge, England: Cambridge University Press.
