---
title: SVD As a Low-Rank Approximation
date: 2025-07-14 11:33:00 +0800
#description: qwer
categories: [math,linear-algebra]
math: true
---
## Singular Value Decomposition

Take a real-valued $m\times n$ matrix $A$. Then its singular value decomposition is the following decomposition.

$$
A = U\Sigma V^T
$$

where $U$ and $V$ are each $m\times m$ and $n \times n$ orthogonal matrices, i.e., $U^T U= I$ and $V^T V = I$, and $\Sigma_{ij} = \lambda_i \delta_{ij}$ where $\lambda_1 \ge \cdots \ge \lambda_n \ge 0$. $\lambda_{ij}$ are the *singular values* of $A$. The singular values are equal to the square roots of the eigenvalues of $A^TA$ ($AA^T$), with eigenvectors $V$ ($U$). 

## Thin SVD, Truncated SVD

Hereinafter, $m > n$ without loss of generality. Then, we can perform *thin SVD*, where we truncate the last $m-n$ rows of $\Sigma$, which results in truncating the last $m-n$ columns of $U$. Now, $U$ is an $m \times n$ left-orthogonal matrix, i.e., $U^T U = I_{n\times n}$.

We can take this process a step further by truncating the singular values, which results in both $U$ and $V$ being truncated. If we leave $r$ largest singular values, then $U$ and $V$ become $m \times r$ and $r \times n$ respectively. Now consider

$$
\tilde{A}=\sum^r_{i=1} u_i\lambda_i v_i^T
$$

where $u_i$ and $v_i$ is the $i$-th column of $U$ and $V$, respectively. This computation is called *truncated SVD*. The resulting matrix is a rank-$r$ matrix $\tilde{A}$.

## Eckart-Young Theorem

> **Theorem** (Eckart-Young) $\tilde{A}$ is the best rank-$r$ approximation of $A$, in terms of both spectral norm (largest singular value) and Frobenius norm. We can easily see that the spectral norm is
$$
||\tilde{A}-A||_2 = \lambda_{r+1}
$$ 
> and Frobenius norm is
$$
||\tilde{A} - A||_F = \sqrt{\sum_{i=r+1}^N \lambda_i^2}
$$

_proof_ We first prove the theorem for the spectral norm. Assume that $\exists B \in M_{m \times n}(\mathbb{R})$ with $\text{rank}(B) = r$ such that
$$||A-B||_2 < ||A-\tilde{A}||_2 = \lambda_{r+1}$$. Take any $w \in \mathrm{null}(B)$. Then the following inequality holds.

$$
||(A-B)w||_2 = ||Aw||_2 < \lambda_{r+1} ||w||_2 \tag{1}
$$

Now take any $w \in \mathrm{span}(v_1, \dots, v_{r+1})$. Then there exist $c_i,\dots,c_{r+1}$ such that

$$
||Aw||_2 = \left \Vert \sum^{r+1}_{i=1} c_i A v_i \right \Vert_2 = \sum^{r+1}_{i=1} |c_i| \lambda_i \ge \lambda_{r+1} ||w||_2 \tag{2}
$$

We know from the rank-nullity theorem that $\mathrm{nullity}(B) = n-r$. Therefore, $\exists w \ne 0$ such that $w \in \mathrm{null}(B) \cap \mathrm{span}(v_1, \dots, v_{r+1})$. However, such a $w$ has to satisfy inequalities (1) and (2), which is contradictory.

Now we prove the theorem for the Frobenius norm.

## References
[1] S.-S. B. Lee, Lecture notes for "Tensor Networks 2022-2"